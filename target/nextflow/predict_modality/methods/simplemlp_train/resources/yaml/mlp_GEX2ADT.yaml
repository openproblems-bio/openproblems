# sample config defaults file
epochs:
  desc: Number of epochs to train over
  value: 10 
batch_size:
  desc: Size of each mini-batch
  value: 512
H1:
  desc: Number of hidden neurons in 1st layer of MLP
  value: 1024 
H2:
  desc: Number of hidden neurons in 2nd layer of MLP
  value: 512
dropout:
  desc: probs of zeroing values
  value: 0
lr:
  desc: learning rate
  value: 0.001
wd:
  desc: weight decay
  value: 1e-5
threshold:
  desc: threshold to set values to zero
  value: 0.05
lr_schedule:
  desc: learning rate scheduler
  value: adam_cosin