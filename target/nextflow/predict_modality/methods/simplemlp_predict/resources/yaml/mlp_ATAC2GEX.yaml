# sample config defaults file
epochs:
  desc: Number of epochs to train over
  value: 10
batch_size:
  desc: Size of each mini-batch
  value: 512
H1:
  desc: Number of hidden neurons in 1st layer of MLP
  value: 256
H2:
  desc: Number of hidden neurons in 2nd layer of MLP
  value: 128
dropout:
  desc: probs of zeroing values
  value: 0.5
lr:
  desc: learning rate
  value: 0.001
wd:
  desc: weight decay
  value: 1e-5
threshold:
  desc: threshold to set values to zero
  value: 0
lr_schedule:
  desc: learning rate scheduler
  value: adam