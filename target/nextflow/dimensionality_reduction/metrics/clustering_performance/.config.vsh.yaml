functionality:
  name: "clustering_performance"
  namespace: "dimensionality_reduction/metrics"
  version: "build_main"
  arguments:
  - type: "file"
    name: "--input_embedding"
    info:
      label: "Embedding"
      summary: "A dataset with dimensionality reduction embedding."
      slots:
        obsm:
        - type: "double"
          name: "X_emb"
          description: "The dimensionally reduced embedding."
          required: true
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - type: "string"
          name: "method_id"
          description: "A unique identifier for the method"
          required: true
        - type: "string"
          name: "normalization_id"
          description: "Which normalization was used"
          required: true
    example:
    - "resources_test/dimensionality_reduction/pancreas/embedding.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "input"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "file"
    name: "--input_solution"
    info:
      label: "Test data"
      summary: "The data for evaluating a dimensionality reduction."
      slots:
        layers:
        - type: "integer"
          name: "counts"
          description: "Raw counts"
          required: true
        - type: "double"
          name: "normalized"
          description: "Normalized expression values"
          required: true
        obs:
        - type: "string"
          name: "cell_type"
          description: "Classification of the cell type based on its characteristics\
            \ and function within the tissue or organism."
          required: true
        var:
        - type: "double"
          name: "hvg_score"
          description: "High variability gene score (normalized dispersion). The greater,\
            \ the more variable."
          required: true
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - name: "dataset_name"
          type: "string"
          description: "Nicely formatted name."
          required: true
        - type: "string"
          name: "dataset_url"
          description: "Link to the original source of the dataset."
          required: false
        - name: "dataset_reference"
          type: "string"
          description: "Bibtex reference of the paper in which the dataset was published."
          required: false
        - name: "dataset_summary"
          type: "string"
          description: "Short description of the dataset."
          required: true
        - name: "dataset_description"
          type: "string"
          description: "Long description of the dataset."
          required: true
        - name: "dataset_organism"
          type: "string"
          description: "The organism of the sample in the dataset."
          required: false
        - type: "string"
          name: "normalization_id"
          description: "Which normalization was used"
          required: true
    example:
    - "resources_test/dimensionality_reduction/pancreas/solution.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "input"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "file"
    name: "--output"
    info:
      label: "Score"
      summary: "Metric score file"
      slots:
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - type: "string"
          name: "normalization_id"
          description: "Which normalization was used"
          required: true
        - type: "string"
          name: "method_id"
          description: "A unique identifier for the method"
          required: true
        - type: "string"
          name: "metric_ids"
          description: "One or more unique metric identifiers"
          multiple: true
          required: true
        - type: "double"
          name: "metric_values"
          description: "The metric values obtained for the given prediction. Must\
            \ be of same length as 'metric_ids'."
          multiple: true
          required: true
    example:
    - "resources_test/dimensionality_reduction/pancreas/score.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  - type: "string"
    name: "--nmi_avg_method"
    description: "Method to compute normalizer in the denominator for normalized mutual\
      \ information score calculation."
    info: null
    default:
    - "arithmetic"
    required: false
    choices:
    - "min"
    - "geometric"
    - "arithmetic"
    - "max"
    direction: "input"
    multiple: false
    multiple_sep: ":"
    dest: "par"
  resources:
  - type: "python_script"
    path: "script.py"
    is_executable: true
  test_resources:
  - type: "file"
    path: "resources_test/dimensionality_reduction/pancreas/"
    dest: "resources_test/dimensionality_reduction/pancreas/"
  - type: "python_script"
    path: "src/common/comp_tests/check_metric_config.py"
    is_executable: true
  - type: "python_script"
    path: "src/common/comp_tests/run_and_check_adata.py"
    is_executable: true
  - type: "file"
    path: "src/common/library.bib"
  info:
    metrics:
    - name: "normalized_mutual_information"
      label: "NMI"
      summary: "Normalized Mutual Information (NMI) is a measure of the concordance\
        \ between clustering obtained from the reduced-dimensional embeddings and\
        \ the cell labels."
      description: "The Normalized Mutual Information (NMI) is a measure of the similarity\
        \ between cluster labels obtained from the clustering of dimensionality reduction\
        \ embeddings and the true cell labels. It is a normalization of the Mutual\
        \ Information (MI) score to scale the results between 0 (no mutual information)\
        \ and 1 (perfect correlation). \nMutual Information quantifies the \"amount\
        \ of information\" obtained about one random variable by observing the other\
        \ random variable. Assuming two label assignments X and Y, it is given by:\
        \ \n  $MI(X,Y) = \\sum_{x=1}^{X}\\sum_{y=1}^{Y}p(x,y)log(\\frac{P(x,y)}{P(x)P'(y)})$,\
        \ \nwhere P(x,y) is the joint probability mass function of X and Y, and P(x),\
        \ P'(y) are the marginal probability mass functions of X and Y respectively.\
        \ The mutual information is normalized by some generalized mean of H(X) and\
        \ H(Y). Therefore, Normalized Mutual Information can be defined as: \n  $NMI(X,Y)\
        \ = \\frac{MI(X,Y)}{mean(H(X),H(Y))}$, \nwhere H(X) and H(Y) are the entropies\
        \ of X and Y respectively. Higher NMI score suggests that the method is effective\
        \ in preserving relevant information.\n"
      reference: "emmons2016analysis"
      documentation_url: "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html"
      repository_url: "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html"
      min: 0
      max: 1
      maximize: true
    - name: "adjusted_rand_index"
      label: "ARI"
      summary: "Adjusted Rand Index (ARI) is a measure of the similarities between\
        \ two cluster assignments of the reduced-dimensional embeddings and the true\
        \ cell types."
      description: "Adjusted Rand Index (ARI) is a measure of similarity between two\
        \ clusterings by considering all pairs of samples and counting pairs that\
        \ are assigned in the same or different clusters in the predicted (from the\
        \ reduced dimensional embeddings) and true clusterings (cell type labels).\
        \ It is the Rand Index (RI) adjusted for chance.\nAssuming the C as the cell\
        \ type labels and K as the clustering of the reduced dimensional embedding,\
        \ Rand Index can be defined as:\n  $RI = \\frac{a + b}{{C}_{2}^{n_{samples}}}$,\n\
        where 'a' is the number of pairs of elements that are in the same set in C\
        \ and in the same set in K, 'b' is the number of pairs of elements that are\
        \ in different sets in C and in different sets in K, and ${C}_{2}^{n_{samples}}$\
        \ is the total number of possible pairs in the dataset. Random label assignments\
        \ can be discounted as follows: \n  $ARI = \\frac{RI - E[RI]}{max(RI) - E[RI]}$,\
        \ \nwhere E[RI] is the expected RI of random labellings.\n"
      reference: "santos2009on"
      documentation_url: "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score"
      repository_url: "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score"
      min: 0
      max: 1
      maximize: true
    type: "metric"
    type_info:
      label: "Metric"
      summary: "A dimensionality reduction metric."
      description: "A metric for evaluating dimensionality reductions.\n"
  status: "enabled"
  set_wd_to_resources_dir: false
platforms:
- type: "docker"
  id: "docker"
  image: "openproblems/base_python:1.0.0"
  target_organization: "openproblems-bio/openproblems"
  target_registry: "ghcr.io"
  namespace_separator: "/"
  resolve_volume: "Automatic"
  chown: true
  setup_strategy: "ifneedbepullelsecachedbuild"
  target_image_source: "https://github.com/openproblems-bio/openproblems"
  setup:
  - type: "python"
    user: false
    packages:
    - "scikit-learn"
    - "scanpy"
    - "leidenalg"
    upgrade: true
  entrypoint: []
  cmd: null
- type: "native"
  id: "native"
- type: "nextflow"
  id: "nextflow"
  directives:
    label:
    - "midtime"
    - "midmem"
    - "midcpu"
    tag: "$id"
  auto:
    simplifyInput: true
    simplifyOutput: false
    transcript: false
    publish: false
  config:
    labels:
      lowmem: "memory = 20.Gb"
      midmem: "memory = 50.Gb"
      highmem: "memory = 100.Gb"
      lowcpu: "cpus = 5"
      midcpu: "cpus = 15"
      highcpu: "cpus = 30"
      lowtime: "time = 1.h"
      midtime: "time = 4.h"
      hightime: "time = 8.h"
      veryhightime: "time = 24.h"
    script:
    - "process.errorStrategy = 'ignore'"
  debug: false
  container: "docker"
info:
  config: "/home/runner/work/openproblems/openproblems/src/tasks/dimensionality_reduction/metrics/clustering_performance/config.vsh.yaml"
  platform: "nextflow"
  output: "/home/runner/work/openproblems/openproblems/target/nextflow/dimensionality_reduction/metrics/clustering_performance"
  executable: "/home/runner/work/openproblems/openproblems/target/nextflow/dimensionality_reduction/metrics/clustering_performance/clustering_performance"
  viash_version: "0.8.6"
  git_commit: "a01361f4ce2cac290991756717f49cbe85815b85"
  git_remote: "https://github.com/openproblems-bio/openproblems"
  git_tag: "v1.0.0-1416-ga01361f4"
