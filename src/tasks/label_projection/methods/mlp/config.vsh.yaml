__merge__: ../../api/comp_method.yaml
functionality:
  name: "mlp"
  info:
    label: Multilayer perceptron
    summary: "A neural network with 100-dimensional PCA input, two hidden layers, and gradient descent weight updates to minimize cross entropy loss."
    description: |
      Multi-Layer Perceptron is a type of artificial neural network that
      consists of multiple layers of interconnected neurons. Each neuron computes a
      weighted sum of all neurons in the previous layer and transforms it with
      nonlinear activation function. The output layer provides the final
      prediction, and network weights are updated by gradient descent to minimize
      the cross entropy loss. Here, the input data is 100-dimensional whitened PCA
      coordinates for each cell, and we use two hidden layers of 100 neurons each.
    reference: "hinton1989connectionist"
    repository_url: https://github.com/scikit-learn/scikit-learn
    documentation_url: "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
    v1:
      path: openproblems/tasks/label_projection/methods/mlp.py
      commit: c2470ce02e6f196267cec1c554ba7ae389c0956a
    preferred_normalization: log_cpm
    variants:
      mlp_log_cpm:
      mlp_scran:
        preferred_normalization: log_scran_pooling
  arguments:
    - name: "--hidden_layer_sizes"
      type: "integer"
      multiple: true
      description: "The ith element represents the number of neurons in the ith hidden layer."
      default: [100, 100]
    - name: "--max_iter"
      type: "integer"
      default: 1000
      description: "Maximum number of iterations"
  resources:
    - type: python_script
      path: script.py
platforms:
  - type: docker
    image: ghcr.io/openproblems-bio/base_python:1.0.0
    setup:
      - type: python
        packages: scikit-learn
  - type: nextflow
    directives: 
      label: [ midmem, lowcpu ]
