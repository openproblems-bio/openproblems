name: Run Tests

on:
  push:
    tags:
      - '*'
    branches-ignore:
      - 'test_docker'
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]

jobs:
  run_tester:
    runs-on: ubuntu-latest

    container:
      image: singlecellopenproblems/openproblems-github-actions:latest
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock
        - /tmp:/tmp
      options: --user root

    if: >-
      !contains(github.event.head_commit.message, 'ci skip') &&
      (
        startsWith(github.ref, 'refs/heads') ||
        github.event.pull_request.draft == false
      )

    steps:
    - name: Cancel Previous Runs
      uses: styfle/cancel-workflow-action@0.6.0
      with:
        access_token: ${{ github.token }}

    - uses: actions/checkout@v2
      with:
        fetch-depth: 0

    - name: Set up environment
      run: |
        echo "LINUX_VERSION=$(uname -a)" >> $GITHUB_ENV
        echo "PYTHON_VERSION=$(python --version)" >> $GITHUB_ENV
        echo "R_VERSION=$(R --version | head -n 1)" >> $GITHUB_ENV

    - name: Cache Python packages
      uses: actions/cache@v2
      with:
        path: ${{ env.PYTHON_VERSION }}
        key: ${{env.LINUX_VERSION}}-pip-${{ env.PYTHON_VERSION }}-${{ hashFiles('setup.py') }}
        restore-keys: ${{env.LINUX_VERSION}}-pip-${{ env.PYTHON_VERSION }}-

    - name: Install package & dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -U wheel setuptools
        pip install -U --editable .[test,r,evaluate]
        python -c "import openproblems"

    - name: Cache R packages
      uses: actions/cache@v2
      if: startsWith(runner.os, 'Linux')
      with:
        path: /usr/local/lib/R/site-library
        key: ${{ env.LINUX_VERSION }}-renv-${{ env.R_VERSION }}-${{ hashFiles('**/renv.lock') }}
        restore-keys: |
          ${{ env.LINUX_VERSION }}-renv-${{ env.R_VERSION }}-

    - name: Install R packages
      run: |
        if (!requireNamespace("renv", quietly = TRUE)) install.packages("renv")
        renv::restore()
        source("./scripts/install_renv.R")
        install_renv("docker/openproblems-r-base/r_requirements.txt")
      shell: Rscript {0}

    - name: Build Docker images
      run: |
        cd workflow
        snakemake -j 4 docker
        cd ..

    - name: Run tests
      run: pytest --cov=openproblems --cov-report=term-missing:skip-covered --cov-report=xml -vv

    - name: Upload coverage
      continue-on-error: ${{ github.repository != 'openproblems-bio/openproblems' }}
      run: codecov --no-color --required --flags unittests

    - name: Upload check results on fail
      if: failure()
      uses: actions/upload-artifact@main
      with:
        name: results
        path: results


  run_benchmark:
    needs: run_tester
    runs-on: self-hosted
    if: >-
      !contains(github.event.head_commit.message, 'ci skip') &&
      github.event_name == 'push'

    env:
      UPDATE_BRANCH_NAME: "auto_update_benchmark_${{ github.run_number }}"
      RESULTS_PATH: "/tmp/${{ github.ref_name }}_results"

    steps:

    - uses: actions/checkout@v2
      with:
        fetch-depth: 1000

    - name: Install system dependencies
      if: ${{ false }} # This is run on the AWS Ubuntu image to generate our custom AMI
      run: |
        sudo apt-get update
        sudo apt-get install -y libhdf5-dev pandoc gfortran libblas-dev liblapack-dev libedit-dev llvm-dev unzip curl
        # Install Python
        sudo apt-get install -y python3.8
        curl https://bootstrap.pypa.io/get-pip.py > get-pip.py
        sudo python3 get-pip.py
        sudo pip3 install --upgrade pip
        # Install Docker
        curl -fsSL https://get.docker.com -o get-docker.sh
        sudo sh get-docker.sh
        # Install Nextflow
        sudo apt-get install -y openjdk-17-jdk
        mkdir /tmp/nextflow
        cd /tmp/nextflow
        wget -qO- get.nextflow.io | bash
        sudo cp /tmp/nextflow/nextflow /usr/local/bin/nextflow
        sudo chmod 755 /usr/local/bin/nextflow
        cd
        nextflow -version
        # Install AWS & S3FS
        sudo apt-get install -y s3fs
        mkdir /tmp/awscli
        cd /tmp/awscli
        curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
        unzip -q awscliv2.zip
        sudo ./aws/install || sudo ./aws/install --update
        aws --version
        # Install Python dependencies
        sudo pip3 install -U wheel setuptools
        sudo pip3 install --ignore-installed --upgrade PyYAML packaging
        sudo pip3 install "openproblems[evaluate] @ git+https://github.com/openproblems-bio/openproblems"
        sudo pip3 uninstall -y openproblems

    - name: Set up environment
      env:
        TOWER_ACCESS_TOKEN: ${{ secrets.TOWER_ACCESS_KEY }}
      run: |
        SCRIPTS_PATH=$(python3 -c 'import os, sysconfig; print(sysconfig.get_path("scripts",f"{os.name}_user"))')
        echo "PATH=${SCRIPTS_PATH}:${PATH}" >> $GITHUB_ENV
        echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
        echo "PYTHON_LOCATION=$(which python3)" >> $GITHUB_ENV
        echo "UBUNTU_VERSION=`grep DISTRIB_RELEASE /etc/lsb-release | sed 's/.*=//g'`" >> $GITHUB_ENV
        # If not on the base repository, append first 6 characters of username to the image name
        # to avoid clashes on ECR
        if [[ "${{ github.repository }}" == "openproblems-bio/openproblems" ]]; \
          then echo "BRANCH=`echo ${{ github.ref }} | sed 's:refs/[a-z]*/::' | sed 's:[/_]:-:g'| head -c 40`"; \
          else echo "BRANCH=`echo ${{ github.repository }} | awk '{print $1}' FS=/ | head -c 6`-`echo ${{ github.ref }} | sed 's:refs/[a-z]*/::' | sed 's:[/_]:-:g'| head -c 33`"; \
        fi >> $GITHUB_ENV
        # don't use tower if the env var is not set
        echo "WITH_TOWER=`if [ $TOWER_ACCESS_TOKEN ]; then echo "-with-tower"; else echo; fi`" >> $GITHUB_ENV
        if [ $(echo ${{ github.ref }} | grep -E -e "^refs/heads/(main|test_benchmark)" -e "^refs/tags") ]; then
          PROFILE="aws"
          RESUME=""
        else
          PROFILE="test,aws"
          RESUME="-resume"
        fi
        echo "PROFILE=$PROFILE" >> $GITHUB_ENV
        echo "RESUME=$RESUME" >> $GITHUB_ENV

    - name: Cache Python packages
      uses: actions/cache@v2
      with:
        path: ${{ env.PYTHON_LOCATION }}
        key: ${{ env.UBUNTU_VERSION }}-pip-${{ env.PYTHON_LOCATION }}-${{ hashFiles('setup.py') }}
        restore-keys: ${{ env.UBUNTU_VERSION}}-pip-${{ env.PYTHON_LOCATION }}-

    - name: Set up S3FS
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-west-2
      run: |
        echo $AWS_ACCESS_KEY_ID:$AWS_SECRET_ACCESS_KEY > ~/.passwd-s3fs
        chmod 600 ~/.passwd-s3fs
        sudo mkdir -p /mnt/openproblems-nextflow
        sudo chown $USER /mnt/openproblems-nextflow
        s3fs -o umask=0277,uid=$(id -u) openproblems-nextflow /mnt/openproblems-nextflow
        # Create bucket/ work/ and cwd/
        for dir in bucket work cwd; do
          mkdir -p /mnt/openproblems-nextflow/${dir}/${{ env.BRANCH }}
        done
        ls -l /mnt/openproblems-nextflow/*/${{ env.BRANCH }}

    - name: Install package & dependencies
      run: |
        sudo pip3 install -U --editable .[evaluate]
        python3 -c "import openproblems"

    - name: Test install
      run: |
        CWD=$(pwd)
        cd /tmp
        openproblems-cli --version
        openproblems-cli --test-hash
        nextflow -version 2> /dev/null
        cd "${CWD}"

    - name: Build Docker images
      run: |
        cd workflow
        snakemake -j 4 docker
        cd ..

    - name: Upload Docker images
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-west-2
      run: |
        ECR_ENDPOINT="490915662541.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com"
        aws ecr get-login-password --region ${AWS_DEFAULT_REGION} | \
          docker login --username AWS --password-stdin $ECR_ENDPOINT
        for image in $(cd docker && ls -1d */ | tr -d '/'); do
          docker tag singlecellopenproblems/${image} ${ECR_ENDPOINT}/openproblems:${BRANCH}-${image}
          docker push --quiet ${ECR_ENDPOINT}/openproblems:${BRANCH}-${image}
        done

    - name: Run benchmark
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        TOWER_ACCESS_TOKEN: ${{ secrets.TOWER_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-west-2
        TOWER_WORKSPACE_ID: 53907369739130
      run: |
        set -eou pipefail
        RUN_NAME="$(echo "$BRANCH" | sed "s/[^a-z]//g")_$(git rev-parse --short HEAD)_${GITHUB_RUN_ATTEMPT}"
        cd /mnt/openproblems-nextflow/cwd/${BRANCH}
        nextflow run $WITH_TOWER \
        -ansi-log false $RESUME \
        -profile $PROFILE \
        -work-dir "/mnt/openproblems-nextflow/work/${BRANCH}" \
        -bucket-dir "s3://openproblems-nextflow/bucket/${BRANCH}" \
        -name "${RUN_NAME}" \
        -e.PYTHONPATH="${PYTHONPATH}" \
        singlecellopenproblems/nf-openproblems \
        --branch ${BRANCH} 2>&1 | \
        grep -v "^WARN: Unable to retrieve AWS batch instance type.*Invalid identifier"

    - name: Copy results
      run: |
        mkdir -p "${RESULTS_PATH}"
        cp -r /mnt/openproblems-nextflow/cwd/${{ env.BRANCH }}/results "${RESULTS_PATH}"

    - name: Parse results
      # There's a bug with the results getting pulled from Nextflow with caching, but
      # this doesn't happen on main, which is the only place `Parse results` is needed
      if: startsWith(github.ref, 'refs/heads/main') || startsWith(github.ref, 'refs/tags')
      run: |
        python workflow/parse_nextflow.py "${RESULTS_PATH}"

    - name: AWS cleanup
      if: success() || startsWith(github.ref, 'refs/heads/main') || startsWith(github.ref, 'refs/tags')
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-west-2
      run: |
        for image in $(cd docker && ls -1d */ | tr -d '/'); do
          aws ecr batch-delete-image --region $AWS_DEFAULT_REGION --repository-name openproblems --image-ids "imageTag=${BRANCH}-${image}"
        done
        aws s3 rm --recursive "s3://openproblems-nextflow/work/${{ env.BRANCH }}"
        aws s3 rm --recursive "s3://openproblems-nextflow/bucket/${{ env.BRANCH }}"
        aws s3 rm --recursive "s3://openproblems-nextflow/cwd/${{ env.BRANCH }}"

    - name: Remove untagged images
      if: startsWith(github.ref, 'refs/heads/main')
      continue-on-error: true
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-west-2
      run: |
        IMAGES_TO_DELETE=$( aws ecr list-images --region $AWS_DEFAULT_REGION --repository-name openproblems --filter "tagStatus=UNTAGGED" --query 'imageIds[*]' --max-items 100 --output json )
        aws ecr batch-delete-image --region $AWS_DEFAULT_REGION --repository-name openproblems --image-ids "$IMAGES_TO_DELETE"

    - name: Pre-commit
      if: startsWith(github.ref, 'refs/tags')
      uses: pre-commit/action@v2.0.0
      continue-on-error: true
      env:
        SKIP: style-files,lintr

    - name: Set up Git branch
      if: startsWith(github.ref, 'refs/tags')
      run: |
        git checkout -b $UPDATE_BRANCH_NAME
        git push -u origin $UPDATE_BRANCH_NAME

    - name: Commit result
      if: startsWith(github.ref, 'refs/tags')
      uses: EndBug/add-and-commit@v6
      with:
        author_name: SingleCellOpenProblems
        author_email: singlecellopenproblems@protonmail.com
        message: 'Update benchmark results # ci skip'
        add: "['website/data/results', 'results.json']"
        branch: ${{ env.UPDATE_BRANCH_NAME }}
        push: false

    - name: Create Pull Request
      if: startsWith(github.ref, 'refs/tags')
      uses: peter-evans/create-pull-request@v3
      with:
        branch: ${{ env.UPDATE_BRANCH_NAME }}
        delete-branch: true
        base: main
        title: '[auto] Update benchmark results'
        reviewers: scottgigante, dburkhardt

    - name: Upload results
      if: always()
      uses: actions/upload-artifact@main
      with:
        name: results
        path: ${{ env.RESULTS_PATH }}
