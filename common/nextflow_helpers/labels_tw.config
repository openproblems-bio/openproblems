def exitStrat(task) {
  println "Determining exit strategy for task (attempt '${task.attempt}', exit status '${task.exitStatus}')"

  // if the component failed 3 times, ignore the error so the workflow can continue
  // it's important 'ignore' is returned even if maxRetries is set to 3,
  // otherwise the workflow will stop
  if (task.attempt >= 3) {
    return 'ignore'
  }
  // when an aws spot instance is reclaimed, nextflow seems to use exit code 2147483647
  // throwing in some extra conditions just in case
  if (exitStatus == null || exitStatus == -1 || exitStatus == 2147483647 || exitStatus == "" || exitStatus == "-") {
    return 'retry'
  }
  // if component failed, retry once
  if (task.exitStatus == 1 && task.attempt < 2) {
    return 'retry'
  }
  // if component ran out of memory, retry with more memory and disk
  if (task.exitStatus in [137, 139]) {
    return 'retry'
  }
  // return 'ignore' for all other cases to ignore the error,
  // otherwise the workflow will stop
  return 'ignore'
}

process {
  executor = 'awsbatch'

  // Default disk space
  disk = 50.GB

  // Retry for exit codes that have something to do with memory issues
  // always retry once
  errorStrategy = { exitStrat(task) }
  maxRetries = 3
  maxMemory = null

  // Resource labels
  withLabel: lowcpu { cpus = 5 }
  withLabel: midcpu { cpus = 15 }
  withLabel: highcpu { cpus = 30 }
  withLabel: lowmem {
    memory = { get_memory( 20.GB * task.attempt ) }
    disk = { 50.GB * task.attempt }
  }
  withLabel: midmem {
    memory = { get_memory( 50.GB * task.attempt ) }
    disk = { 100.GB * task.attempt }
  }
  withLabel: highmem {
    memory = { get_memory( 100.GB * task.attempt ) }
    disk = { 200.GB * task.attempt }
  }
  withLabel: veryhighmem {
    memory = { get_memory( 200.GB * task.attempt ) }
    disk = { 400.GB * task.attempt }
  }
  withLabel: lowsharedmem {
    containerOptions = { workflow.containerEngine != 'singularity' ? "--shm-size ${String.format("%.0f",task.memory.mega * 0.05)}" : ""}
  }
  withLabel: midsharedmem {
    containerOptions = { workflow.containerEngine != 'singularity' ? "--shm-size ${String.format("%.0f",task.memory.mega * 0.1)}" : ""}
  }
  withLabel: highsharedmem {
    containerOptions = { workflow.containerEngine != 'singularity' ? "--shm-size ${String.format("%.0f",task.memory.mega * 0.25)}" : ""}
  }
  withLabel: gpu {
    cpus = 16
    accelerator = 1
    queue = "TowerForge-4bCgEHRoFmQ6YLQ3WULEdU-work"
    containerOptions = { workflow.containerEngine == "singularity" ? '--nv':
       ( workflow.containerEngine == "docker" ? '--gpus all': null ) }
  }
  withLabel: midgpu {
    cpus = 32
    accelerator = 4
    queue = "TowerForge-4bCgEHRoFmQ6YLQ3WULEdU-work"
    containerOptions = { workflow.containerEngine == "singularity" ? '--nv':
       ( workflow.containerEngine == "docker" ? '--gpus all': null ) }
  }
  withLabel: highgpu {
    cpus = 64
    accelerator = 8
    queue = "TowerForge-4bCgEHRoFmQ6YLQ3WULEdU-work"
    containerOptions = { workflow.containerEngine == "singularity" ? '--nv':
       ( workflow.containerEngine == "docker" ? '--gpus all': null ) }
  }
  withLabel: biggpu {
    cpus = 16
    accelerator = 1
    queue = "TowerForge-3NzuFGWtGTkPGu2u0iwZY2-work"
    containerOptions = { workflow.containerEngine == "singularity" ? '--nv':
       ( workflow.containerEngine == "docker" ? '--gpus all': null ) }
  }

  // make sure publishstates gets enough disk space and memory
  withName:'.*publishStatesProc' {
    memory = '16GB'
    disk = '100GB'
  }
}

def get_memory(to_compare) {
  if (!process.containsKey("maxMemory") || !process.maxMemory) {
    return to_compare
  }

  try {
    if (process.containsKey("maxRetries") && process.maxRetries && task.attempt == (process.maxRetries as int)) {
      return process.maxMemory
    }
    else if (to_compare.compareTo(process.maxMemory as nextflow.util.MemoryUnit) == 1) {
      return max_memory as nextflow.util.MemoryUnit
    }
    else {
      return to_compare
    }
  } catch (all) {
        println "Error processing memory resources. Please check that process.maxMemory '${process.maxMemory}' and process.maxRetries '${process.maxRetries}' are valid!"
        System.exit(1)
  }
}

// set tracing file
trace {
    enabled = true
    overwrite = true
    file = "${params.publish_dir}/trace.txt"
}

aws.batch.maxSpotAttempts = 5
google.batch.maxSpotAttempts = 5
